# Обзор кодовой базы проекта DuoNiche Backend

## 1. Общее назначение проекта

DuoNiche Backend — это бэкенд-сервис, построенный на базе фреймворка FastAPI. Его основная задача — обеспечивать логику для Telegram-бота по изучению языков. Сервис использует Large Language Models (LLMs) для генерации учебных упражнений и автоматической проверки ответов пользователей. Он также управляет прогрессом пользователей, обрабатывает платежи (через Telegram Stars) и планирует уведомления.

## 2. Структура проекта
Проект имеет следующую основную структуру директорий:
```text
.
├── .github/              # Конфигурации GitHub Actions (CI/CD)
│ └── workflows/
│       └── deploy.yml    # Workflow деплоя на прод
├── alembic/              # Скрипты миграций базы данных (SQLAlchemy Alembic)
│   ├── versions/         # Файлы конкретных версий миграций
│   ├── env.py            # Среда выполнения миграций
│   └── ...
├── app/                  # Основной пакет приложения
│   ├── api/              # Определение HTTP API (FastAPI)
│   │   ├── schemas/      # Pydantic схемы для запросов/ответов API
│   │   └── v1/           # Версионирование API (v1)
│   │       ├── endpoints/ # Обработчики конкретных эндпоинтов
│   │       └── api.py     # Роутер для API v1
│   ├── core/             # Основная бизнес-логика и доменные сущности
│   │   ├── entities/     # Pydantic модели доменных сущностей
│   │   ├── interfaces/   # Абстрактные базовые классы (интерфейсы)
│   │   ├── repositories/ # Абстрактные базовые классы (интерфейсы) для репозиториев
│   │   ├── services/     # Сервисы бизнес-логики
│   │   └── value_objects/ # Value Objects
│   ├── db/               # Взаимодействие с базой данных
│   │   ├── models/       # SQLAlchemy ORM модели
│   │   ├── repositories/ # Реализации репозиториев на SQLAlchemy
│   │   └── db.py         # Настройка движка БД и сессий
│   ├── infrastructure/   # Внешние инфраструктурные зависимости (Redis)
│   │   └── redis_client.py
│   ├── llm/              # Логика взаимодействия с LLM
│   │   ├── assessors/    # Оценщики качества упражнений
│   │   ├── generators/   # Генераторы упражнений на базе LLM
│   │   ├── interfaces/   # Интерфейсы генераторов/валидаторов LLM
│   │   ├── validators/   # Валидаторы ответов на базе LLM
│   │   ├── factories.py  # Фабрики для создания генераторов/валидаторов
│   │   ├── llm_base.py   # Базовый класс для LLM сервисов
│   │   ├── llm_service.py # Сервис для генерации и валидации через LLM
│   │   └── llm_translator.py # Сервис для перевода через LLM
│   ├── services/         # Клиенты внешних сервисов (TTS, File Storage)
│   │   ├── file_storage_service.py # Клиент для Cloudflare R2
│   │   ├── google_translator.py    # Клиент Google Translate
│   │   ├── notification_producer.py # Сервис для постановки задач уведомлений
│   │   └── tts_service.py          # Клиент Google Text-to-Speech
│   ├── utils/            # Вспомогательные утилиты
│   ├── workers/          # Фоновые воркеры
│   │   ├── arq_tasks/    # Задачи для ARQ воркера (например, отчеты)
│   │   ├── exercise_quality_monitor.py # Мониторинг качества упражнений
│   │   ├── exercise_review_processor.py # Обработка упражнений, отправленных на проверку
│   │   ├── exercise_stock_refill.py # Пополнение запаса упражнений
│   │   ├── metrics_updater.py # Обновление пользовательских метрик
│   │   └── notification_scheduler.py # Планирование уведомлений
│   ├── arq_config.py     # Конфигурация ARQ воркера
│   ├── celery_producer.py # Настройка Celery клиента
│   ├── config.py         # Настройки приложения
│   ├── main.py           # Точка входа FastAPI приложения
│   └── ...
├── docs/                 # Документация проекта
│   ├── project_overview_en.md # Английская версия обзора
│   └── project_overview_ru.md # Этот файл
├── infra/                # Конфигурации инфраструктуры (Docker Compose, Nginx)
├── tests/                # Тесты
├── Dockerfile            # Dockerfile для сборки образа приложения
├── entrypoint.sh         # Скрипт точки входа Docker контейнера
├── pyproject.toml        # Конфигурация проекта (uv, ruff, mypy, pytest)
└── README.md             # Документация проекта
```

## 3. Ключевые модули и их функционал

- **`app/main.py`**: Точка входа FastAPI приложения. Определяет `lifespan` для инициализации и корректного завершения ресурсов (БД, Redis, HTTPX клиент, LLM сервисы). Запускает фоновые воркеры при старте.
- **`app/core/`**: Содержит основную бизнес-логику и доменные сущности приложения, стремясь к независимости от конкретных фреймворков и внешних сервисов.
  - **`services/`**: Классы-сервисы, инкапсулирующие бизнес-логику (например, `UserProgressService`, `ExerciseService`, `PaymentService`).
  - **`entities/`**: Pydantic модели, представляющие основные доменные сущности (например, `User`, `Exercise`, `UserBotProfile`).
- **`app/db/`**: Уровень доступа к данным, реализующий взаимодействие с базой данных PostgreSQL с использованием SQLAlchemy.
- **`app/llm/`**: Интеграция с Large Language Models (LLMs), в основном через библиотеку LangChain для взаимодействия с OpenAI API.
  - **`generators/`**: Модули с классами-генераторами для различных типов упражнений. `choose_accent_generator.py` является особым случаем и использует веб-скрапинг вместо LLM.
  - **`validators/`**: Модули с классами-валидаторами для проверки ответов пользователей.
  - **`assessors/`**: Содержит логику для оценки качества упражнений.
- **`app/services/`**: Клиенты для работы с внешними сервисами.
  - **`tts_service.py`**: Интеграция с Google Text-to-Speech для генерации аудио к упражнениям.
  - **`file_storage_service.py`**: Обрабатывает загрузку файлов в Cloudflare R2.
  - **`notification_producer.py`**: Создает и ставит задачи уведомлений в очередь Celery.
- **`app/workers/` и `app/arq_config.py`**: Содержит фоновые задачи (воркеры).
  - **`arq_config.py`** настраивает ARQ воркер для отложенных задач (например, генерация отчетов).
  - **`exercise_stock_refill.py`**: Периодически генерирует новые упражнения для пополнения запаса.
  - **`exercise_quality_monitor.py` и `exercise_review_processor.py`**: Совместно работают для автоматической оценки качества упражнений на основе производительности пользователей и анализа LLM.
  - **`notification_scheduler.py`**: Периодически проверяет профили пользователей для планирования уведомлений (например, о готовности сессии или долгом перерыве).
- **`infra/`**: Конфигурации для развертывания приложения с использованием Docker и Docker Compose, включая настройки для PostgreSQL, Redis, Nginx и Prometheus.
- **`tests/`** Автоматические тесты для различных частей приложения, используя pytest. Включает юнит-тесты, интеграционные тесты и тесты API.


## 4. Основные сценарии использования (Workflows)

1.  **Регистрация/Обновление пользователя:**
    - Telegram-бот отправляет данные пользователя (telegram_id, username, язык и т.д.) на эндпоинт `PUT /api/v1/users/`.
    - `UserService` и `UserBotProfileService` создают или обновляют запись о пользователе и его профиль для конкретного бота (языка).

2.  **Получение следующего действия/упражнения:**
    - Telegram-бот запрашивает `GET /api/v1/users/{user_id}/bots/{bot_id}/next-action/`.
    - `UserProgressService` анализирует состояние пользователя (прогресс, лимиты) и определяет следующее действие: вернуть новое упражнение, сообщение о достижении лимита или предложение об оплате для досрочной разблокировки.

3.  **Ответ на упражнение и валидация:**
    - Telegram-бот отправляет ответ пользователя на эндпоинт `POST /api/v1/exercises/{exercise_id}/validate/` (или легаси для миниапп `POST /api/v1/exercises/validate/`).
    - `ExerciseService` (через `AttemptValidator`) проверяет кеш, затем базу данных на наличие ранее проверенного ответа. Если ответ не найден, используется `LLMService` для его валидации. Результат кешируется, сохраняется в БД и возвращается пользователю.

4.  **Обработка платежа (Telegram Stars) для разблокировки сессии:**
    - После успешной оплаты в Telegram, бот отправляет данные платежа на эндпоинт `POST /api/v1/users/{user_id}/bots/{bot_id}/payments/unlock-session`.
    - `PaymentService` записывает информацию о платеже, а `UserBotProfileService` сбрасывает счетчики упражнений и время заморозки, начиная новую сессию.

5.  **Фоновая генерация упражнений:**
   - Воркер `exercise_stock_refill_loop` периодически проверяет количество неиспользованных упражнений в БД и генерирует новые с помощью `LLMService`, если их запас мал.

6.  **Фоновая генерация аудио для упражнений `StoryComprehension`**:
    - Когда генерируется упражнение типа `StoryComprehension`, воркер `exercise_stock_refill` вызывает `tts_service` для синтеза речи.
    - Полученный аудиофайл загружается в Cloudflare R2 через `file_storage_service`, а `file_id` для Telegram кэшируется. URL и `file_id` сохраняются в данных упражнения.

7.  **Автоматический мониторинг качества и проверка упражнений**:
    - Воркер `exercise_quality_monitor` периодически рассчитывает взвешенный рейтинг ошибок для каждого упражнения. Если рейтинг ошибок превышает порог, упражнению присваивается статус `PENDING_REVIEW`.
    - Воркер `exercise_review_processor` забирает такие упражнения, использует LLM для их анализа и принимает решение: вернуть в `PUBLISHED`, отправить на ручную проверку (`PENDING_ADMIN_REVIEW`) или заархивировать (`ARCHIVED`).

8.  **Генерация и отправка детальных еженедельных отчетов по запросу**:
    - Пользователь запрашивает детальный отчет через эндпоинт. `UserReportService` ставит задачу `generate_and_send_detailed_report_arq` в очередь ARQ.
    - Воркер ARQ генерирует текст отчета с помощью LLM, сохраняет его в БД и планирует отложенную задачу на отправку уведомления через несколько минут.

## 5. Зависимости и интеграции

- **Основной фреймворк:** FastAPI
- **Асинхронная работа:** asyncio
- **База данных:** PostgreSQL (используется с асинхронным драйвером `asyncpg` и ORM `SQLAlchemy 2.0`)
- **Миграции БД:** Alembic
- **Кэширование/Очереди:**
  - **Redis**: Используется для асинхронного кэширования задач и как брокер для Celery и ARQ.
  - **Celery**: Используется как продюсер для отправки задач в отдельный сервис Notifier.
  - **ARQ**: Используется для обработки асинхронных фоновых задач, таких как генерация отчетов.
- **LLM (Large Language Models):** OpenAI API (через библиотеку `LangChain`)
- **Text-to-Speech (TTS)**: Google GenAI API
- **Хранилище файлов**: Cloudflare R2 (S3-совместимое, через `aioboto3`)
- **HTTP-клиент:** `httpx` (для исходящих асинхронных запросов, например, к API LLM или внешним сайтам для скраппинга)
- **Метрики:** Prometheus (через `prometheus-client` и `prometheus-fastapi-instrumentator`)
- **Логирование ошибок:** Sentry (через `sentry-sdk`)
- **Конфигурация:** `pydantic-settings` (для загрузки настроек из переменных окружения и `.env` файлов)
- **Скраппинг:** `lxml` (используется в `app/services/choose_accent_generator.py`)
- **CI/CD:** GitHub Actions (для сборки Docker-образа и деплоя)
- **Управление зависимостями и инструментами разработки:** `uv` (для управления зависимостями), `pyproject.toml` (конфигурация `ruff` для линтинга и форматирования, `mypy` для статической типизации, `pytest` для тестирования)
- **Инструменты для разработки:** `pre-commit` (для автоматического применения хуков перед коммитом)

---